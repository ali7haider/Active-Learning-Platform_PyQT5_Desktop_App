# -*- coding: utf-8 -*-
"""Multi-Objective Code_Two Objectives.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ZGSgKbTConIeKFi-OE5YLtwoK00JtOZY
"""

import numpy as np
from numpy import loadtxt, savetxt

import pandas as pd
import math
import time
from datetime import date
# print options

np.set_printoptions(formatter={'float': lambda x: "{0:0.3f}".format(x)})

## torch dependencies
import torch
torch.cuda.empty_cache()

tkwargs = {"dtype": torch.double,  # set as double to minimize zero error for cholesky decomposition error
          "device": torch.device("cuda" if torch.cuda.is_available() else "cpu")} # set tensors to GPU,
#if multiple GPUs please set cuda:x properly

torch.set_printoptions(precision=3)

## Optimisation & DoE
# botorch dependencies
import botorch

# data related
from botorch.utils.sampling import draw_sobol_samples
from botorch.utils.transforms import unnormalize, normalize

# surrogate model specific
from botorch.models.gp_regression import SingleTaskGP
from botorch.models.model_list_gp_regression import ModelListGP
from botorch.models.transforms.outcome import Standardize
from botorch import fit_gpytorch_mll


# utilities
from botorch.optim.optimize import optimize_acqf,optimize_acqf_list
from botorch.sampling import SobolQMCNormalSampler
from botorch.utils.multi_objective.pareto import is_non_dominated
from botorch.utils.multi_objective.hypervolume import Hypervolume
from typing import Optional
from torch import Tensor
from botorch.exceptions import BadInitialCandidatesWarning
from botorch.utils.sampling import sample_simplex
from torch.optim import SGD
from gpytorch.mlls.sum_marginal_log_likelihood import SumMarginalLogLikelihood
from botorch.acquisition.objective import GenericMCObjective
from botorch.utils.multi_objective.scalarization import get_chebyshev_scalarization
from botorch.acquisition.monte_carlo import qNoisyExpectedImprovement
from botorch.acquisition.multi_objective.logei import qLogNoisyExpectedHypervolumeImprovement
from botorch.acquisition.multi_objective.objective import IdentityMCMultiOutputObjective

# LHS

# Warnings
import warnings
warnings.filterwarnings('ignore', category=BadInitialCandidatesWarning)
warnings.filterwarnings('ignore', category=RuntimeWarning)

##############################################################################################################

# plotting dependencies
from matplotlib import pyplot as plt
import seaborn as sns
import matplotlib.cm as cm
import matplotlib.patches as patches
import matplotlib.lines as lines

df = pd.read_csv("Polymer_ISChE_Data.csv")
df.head()

"""#### Optimization Boundary"""

lower_bounds = torch.tensor([1, 1, 1, 1], **tkwargs) # to be specified by user
upper_bounds = torch.tensor([10, 5, 5, 5], **tkwargs)
problem_bounds = torch.vstack([lower_bounds, upper_bounds])

n_var = 4
n_obj = 2


random_state = 42
torch.manual_seed(random_state)

# set the tensor according to latest cumulative dataset
train_x = torch.tensor(df.iloc[:,:n_var].to_numpy(), **tkwargs)
train_obj = torch.tensor(df.iloc[:,n_var:n_var+n_obj].to_numpy(), **tkwargs)


# Standard bounds i.e. 0 and 1 for normalization
standard_bounds = torch.zeros(2, train_x.shape[1], **tkwargs)
standard_bounds[1] = 1

train_x_norm = normalize(train_x, problem_bounds)

## Train Gaussian process regression model

models = []
for i in range(train_obj.shape[-1]): # Train 3 seperate GP models for each objective
    train_y = train_obj[..., i : i + 1]
    models.append(SingleTaskGP(train_x_norm, train_y, outcome_transform=Standardize(m=1)))
model = ModelListGP(*models) # stack models
mll = SumMarginalLogLikelihood(model.likelihood, model)

fit_gpytorch_mll(mll); # fit model

"""### Specified by user"""

# to be specified by user
ref_point = torch.tensor([0, 0])

BATCH_SIZE = 5 # Define desired number of candidates

NUM_RESTARTS = 10
RAW_SAMPLES = 128

acq_func = qLogNoisyExpectedHypervolumeImprovement(
    model=model,
    ref_point=ref_point,
    X_baseline=train_x_norm,
    sampler=SobolQMCNormalSampler(torch.Size([512])),# determines how candidates are randomly proposed before selection
    objective=IdentityMCMultiOutputObjective(outcomes=np.arange(n_obj).tolist()), # optimize first n_obj col
    prune_baseline=True,
    cache_pending=True
)


candidates, _ = optimize_acqf(
    acq_function=acq_func,
    q = BATCH_SIZE,
    bounds=standard_bounds,
    num_restarts=NUM_RESTARTS,
    raw_samples=RAW_SAMPLES,
    options = {"batch_limit":5, "maxiter": 200}

)

# unnormalize
new_x = unnormalize(candidates.detach(), bounds=problem_bounds)
new_x = new_x.cpu().numpy()

# Generate 50 optimized candidates
df_candidates= pd.DataFrame(new_x, columns=df.columns[:4])
df_candidates = df_candidates.round(2)
df_candidates

